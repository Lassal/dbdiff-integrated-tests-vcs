schema: SYS
name: DBMS_DATAPUMP
routineType: PACKAGE
returnParamater:
  name: OPEN.(--return--)
  ordinalPosition: 0
  dataType: NUMBER
  parameterMode: OUT
parameters:
- name: ADD_DEVICE.HANDLE
  ordinalPosition: 1
  dataType: NUMBER
  parameterMode: IN
- name: ADD_DEVICE.DEVICENAME
  ordinalPosition: 2
  dataType: VARCHAR2
  parameterMode: IN
- name: ADD_DEVICE.VOLUMESIZE
  ordinalPosition: 3
  dataType: VARCHAR2
  parameterMode: IN
- name: ADD_FILE.HANDLE
  ordinalPosition: 1
  dataType: NUMBER
  parameterMode: IN
- name: ADD_FILE.FILENAME
  ordinalPosition: 2
  dataType: VARCHAR2
  parameterMode: IN
- name: ADD_FILE.DIRECTORY
  ordinalPosition: 3
  dataType: VARCHAR2
  parameterMode: IN
- name: ADD_FILE.FILESIZE
  ordinalPosition: 4
  dataType: VARCHAR2
  parameterMode: IN
- name: ADD_FILE.FILETYPE
  ordinalPosition: 5
  dataType: NUMBER
  parameterMode: IN
- name: ADD_FILE.REUSEFILE
  ordinalPosition: 6
  dataType: NUMBER
  parameterMode: IN
- name: ATTACH.JOB_NAME
  ordinalPosition: 1
  dataType: VARCHAR2
  parameterMode: IN
- name: ATTACH.JOB_OWNER
  ordinalPosition: 2
  dataType: VARCHAR2
  parameterMode: IN
- name: CLIENT_LOB_APPEND.VALUE
  ordinalPosition: 1
  dataType: VARCHAR2
  parameterMode: IN
- name: CLIENT_LOB_APPEND.POSITION
  ordinalPosition: 2
  dataType: NUMBER
  parameterMode: IN
- name: CLIENT_LOB_APPEND.AS_IS
  ordinalPosition: 3
  dataType: NUMBER
  parameterMode: IN
- name: CREATE_JOB_VIEW(1).JOB_SCHEMA
  ordinalPosition: 1
  dataType: VARCHAR2
  parameterMode: IN
- name: CREATE_JOB_VIEW(1).JOB_NAME
  ordinalPosition: 2
  dataType: VARCHAR2
  parameterMode: IN
- name: CREATE_JOB_VIEW(1).VIEW_NAME
  ordinalPosition: 3
  dataType: VARCHAR2
  parameterMode: IN
- name: CREATE_JOB_VIEW(1).VIEW_TYPE
  ordinalPosition: 4
  dataType: NUMBER
  parameterMode: IN
- name: CREATE_JOB_VIEW(2).HANDLE
  ordinalPosition: 1
  dataType: NUMBER
  parameterMode: IN
- name: CREATE_JOB_VIEW(2).VIEW_NAME
  ordinalPosition: 2
  dataType: VARCHAR2
  parameterMode: IN
- name: CREATE_JOB_VIEW(2).VIEW_TYPE
  ordinalPosition: 3
  dataType: NUMBER
  parameterMode: IN
- name: DATA_FILTER(1).HANDLE
  ordinalPosition: 1
  dataType: NUMBER
  parameterMode: IN
- name: DATA_FILTER(1).NAME
  ordinalPosition: 2
  dataType: VARCHAR2
  parameterMode: IN
- name: DATA_FILTER(1).VALUE
  ordinalPosition: 3
  dataType: NUMBER
  parameterMode: IN
- name: DATA_FILTER(1).TABLE_NAME
  ordinalPosition: 4
  dataType: VARCHAR2
  parameterMode: IN
- name: DATA_FILTER(1).SCHEMA_NAME
  ordinalPosition: 5
  dataType: VARCHAR2
  parameterMode: IN
- name: DATA_FILTER(2).HANDLE
  ordinalPosition: 1
  dataType: NUMBER
  parameterMode: IN
- name: DATA_FILTER(2).NAME
  ordinalPosition: 2
  dataType: VARCHAR2
  parameterMode: IN
- name: DATA_FILTER(2).VALUE
  ordinalPosition: 3
  dataType: CLOB
  parameterMode: IN
- name: DATA_FILTER(2).TABLE_NAME
  ordinalPosition: 4
  dataType: VARCHAR2
  parameterMode: IN
- name: DATA_FILTER(2).SCHEMA_NAME
  ordinalPosition: 5
  dataType: VARCHAR2
  parameterMode: IN
- name: DATA_FILTER(3).HANDLE
  ordinalPosition: 1
  dataType: NUMBER
  parameterMode: IN
- name: DATA_FILTER(3).NAME
  ordinalPosition: 2
  dataType: VARCHAR2
  parameterMode: IN
- name: DATA_FILTER(3).VALUE
  ordinalPosition: 3
  dataType: VARCHAR2
  parameterMode: IN
- name: DATA_FILTER(3).TABLE_NAME
  ordinalPosition: 4
  dataType: VARCHAR2
  parameterMode: IN
- name: DATA_FILTER(3).SCHEMA_NAME
  ordinalPosition: 5
  dataType: VARCHAR2
  parameterMode: IN
- name: DATA_REMAP.HANDLE
  ordinalPosition: 1
  dataType: NUMBER
  parameterMode: IN
- name: DATA_REMAP.NAME
  ordinalPosition: 2
  dataType: VARCHAR2
  parameterMode: IN
- name: DATA_REMAP.TABLE_NAME
  ordinalPosition: 3
  dataType: VARCHAR2
  parameterMode: IN
- name: DATA_REMAP.COLUMN
  ordinalPosition: 4
  dataType: VARCHAR2
  parameterMode: IN
- name: DATA_REMAP.FUNCTION
  ordinalPosition: 5
  dataType: VARCHAR2
  parameterMode: IN
- name: DATA_REMAP.SCHEMA
  ordinalPosition: 6
  dataType: VARCHAR2
  parameterMode: IN
- name: DATA_REMAP.REMAP_FLAGS
  ordinalPosition: 7
  dataType: NUMBER
  parameterMode: IN
- name: DETACH.HANDLE
  ordinalPosition: 1
  dataType: NUMBER
  parameterMode: IN
- name: DH_KEY_EXCHANGE.HANDLE
  ordinalPosition: 1
  dataType: NUMBER
  parameterMode: IN
- name: DH_KEY_EXCHANGE.A
  ordinalPosition: 2
  dataType: VARCHAR2
  parameterMode: IN
- name: DH_KEY_EXCHANGE.B
  ordinalPosition: 3
  dataType: VARCHAR2
  parameterMode: IN
- name: DH_KEY_EXCHANGE.C
  ordinalPosition: 4
  dataType: VARCHAR2
  parameterMode: OUT
- name: DH_KEY_EXCHANGE.D
  ordinalPosition: 5
  dataType: VARCHAR2
  parameterMode: OUT
- name: ESTABLISH_REMOTE_CONTEXT.WORKER_ID
  ordinalPosition: 1
  dataType: NUMBER
  parameterMode: IN
- name: ESTABLISH_REMOTE_CONTEXT.REMOTE_LINK
  ordinalPosition: 2
  dataType: VARCHAR2
  parameterMode: IN
- name: GET_DUMPFILE_INFO.FILENAME
  ordinalPosition: 1
  dataType: VARCHAR2
  parameterMode: IN
- name: GET_DUMPFILE_INFO.DIRECTORY
  ordinalPosition: 2
  dataType: VARCHAR2
  parameterMode: IN
- name: GET_DUMPFILE_INFO.INFO_TABLE
  ordinalPosition: 3
  dataType: TABLE
  parameterMode: OUT
- name: GET_DUMPFILE_INFO.FILETYPE
  ordinalPosition: 4
  dataType: NUMBER
  parameterMode: OUT
- name: GET_STATUS(1).HANDLE
  ordinalPosition: 1
  dataType: NUMBER
  parameterMode: IN
- name: GET_STATUS(1).MASK
  ordinalPosition: 2
  dataType: NUMBER
  numericPrecision: 38
  parameterMode: IN
- name: GET_STATUS(1).TIMEOUT
  ordinalPosition: 3
  dataType: NUMBER
  parameterMode: IN
- name: GET_STATUS(2).HANDLE
  ordinalPosition: 1
  dataType: NUMBER
  parameterMode: IN
- name: GET_STATUS(2).MASK
  ordinalPosition: 2
  dataType: NUMBER
  numericPrecision: 38
  parameterMode: IN
- name: GET_STATUS(2).TIMEOUT
  ordinalPosition: 3
  dataType: NUMBER
  parameterMode: IN
- name: GET_STATUS(2).JOB_STATE
  ordinalPosition: 4
  dataType: VARCHAR2
  parameterMode: OUT
- name: GET_STATUS(2).STATUS
  ordinalPosition: 5
  dataType: OBJECT
  parameterMode: OUT
- name: GET_STATUS(3).HANDLE
  ordinalPosition: 1
  dataType: NUMBER
  parameterMode: IN
- name: GET_STATUS(3).MASK
  ordinalPosition: 2
  dataType: NUMBER
  numericPrecision: 38
  parameterMode: IN
- name: GET_STATUS(3).TIMEOUT
  ordinalPosition: 3
  dataType: NUMBER
  parameterMode: IN
- name: GET_STATUS(3).JOB_STATE
  ordinalPosition: 4
  dataType: VARCHAR2
  parameterMode: OUT
- name: GET_STATUS(3).STATUS
  ordinalPosition: 5
  dataType: OBJECT
  parameterMode: OUT
- name: GET_STATUS(4).HANDLE
  ordinalPosition: 1
  dataType: NUMBER
  parameterMode: IN
- name: GET_STATUS(4).MASK
  ordinalPosition: 2
  dataType: NUMBER
  numericPrecision: 38
  parameterMode: IN
- name: GET_STATUS(4).TIMEOUT
  ordinalPosition: 3
  dataType: NUMBER
  parameterMode: IN
- name: GET_STATUS(4).JOB_STATE
  ordinalPosition: 4
  dataType: VARCHAR2
  parameterMode: OUT
- name: GET_STATUS(4).STATUS
  ordinalPosition: 5
  dataType: OBJECT
  parameterMode: OUT
- name: GET_STATUS(5).HANDLE
  ordinalPosition: 1
  dataType: NUMBER
  parameterMode: IN
- name: GET_STATUS(5).MASK
  ordinalPosition: 2
  dataType: NUMBER
  numericPrecision: 38
  parameterMode: IN
- name: GET_STATUS(5).TIMEOUT
  ordinalPosition: 3
  dataType: NUMBER
  parameterMode: IN
- name: GET_STATUS(5).JOB_STATE
  ordinalPosition: 4
  dataType: VARCHAR2
  parameterMode: OUT
- name: GET_STATUS(5).STATUS
  ordinalPosition: 5
  dataType: OBJECT
  parameterMode: OUT
- name: GET_STATUS_VERSION.VERSION
  ordinalPosition: 1
  dataType: NUMBER
  parameterMode: IN
- name: HAS_PRIVS.OPER
  ordinalPosition: 1
  dataType: VARCHAR2
  parameterMode: IN
- name: LOG_ENTRY.HANDLE
  ordinalPosition: 1
  dataType: NUMBER
  parameterMode: IN
- name: LOG_ENTRY.MESSAGE
  ordinalPosition: 2
  dataType: VARCHAR2
  parameterMode: IN
- name: LOG_ENTRY.LOG_FILE_ONLY
  ordinalPosition: 3
  dataType: NUMBER
  parameterMode: IN
- name: LOG_ERROR.HANDLE
  ordinalPosition: 1
  dataType: NUMBER
  parameterMode: IN
- name: LOG_ERROR.MESSAGE
  ordinalPosition: 2
  dataType: VARCHAR2
  parameterMode: IN
- name: LOG_ERROR.ERROR_NUMBER
  ordinalPosition: 3
  dataType: NUMBER
  parameterMode: IN
- name: LOG_ERROR.FATAL_ERROR
  ordinalPosition: 4
  dataType: NUMBER
  parameterMode: IN
- name: LOG_ERROR.LOG_FILE_ONLY
  ordinalPosition: 5
  dataType: NUMBER
  parameterMode: IN
- name: METADATA_FILTER(1).HANDLE
  ordinalPosition: 1
  dataType: NUMBER
  parameterMode: IN
- name: METADATA_FILTER(1).NAME
  ordinalPosition: 2
  dataType: VARCHAR2
  parameterMode: IN
- name: METADATA_FILTER(1).VALUE
  ordinalPosition: 3
  dataType: VARCHAR2
  parameterMode: IN
- name: METADATA_FILTER(1).OBJECT_PATH
  ordinalPosition: 4
  dataType: VARCHAR2
  parameterMode: IN
- name: METADATA_FILTER(1).OBJECT_TYPE
  ordinalPosition: 5
  dataType: VARCHAR2
  parameterMode: IN
- name: METADATA_FILTER(2).HANDLE
  ordinalPosition: 1
  dataType: NUMBER
  parameterMode: IN
- name: METADATA_FILTER(2).NAME
  ordinalPosition: 2
  dataType: VARCHAR2
  parameterMode: IN
- name: METADATA_FILTER(2).VALUE
  ordinalPosition: 3
  dataType: CLOB
  parameterMode: IN
- name: METADATA_FILTER(2).OBJECT_PATH
  ordinalPosition: 4
  dataType: VARCHAR2
  parameterMode: IN
- name: METADATA_FILTER(2).OBJECT_TYPE
  ordinalPosition: 5
  dataType: VARCHAR2
  parameterMode: IN
- name: METADATA_REMAP.HANDLE
  ordinalPosition: 1
  dataType: NUMBER
  parameterMode: IN
- name: METADATA_REMAP.NAME
  ordinalPosition: 2
  dataType: VARCHAR2
  parameterMode: IN
- name: METADATA_REMAP.OLD_VALUE
  ordinalPosition: 3
  dataType: VARCHAR2
  parameterMode: IN
- name: METADATA_REMAP.VALUE
  ordinalPosition: 4
  dataType: VARCHAR2
  parameterMode: IN
- name: METADATA_REMAP.OBJECT_TYPE
  ordinalPosition: 5
  dataType: VARCHAR2
  parameterMode: IN
- name: METADATA_TRANSFORM(1).HANDLE
  ordinalPosition: 1
  dataType: NUMBER
  parameterMode: IN
- name: METADATA_TRANSFORM(1).NAME
  ordinalPosition: 2
  dataType: VARCHAR2
  parameterMode: IN
- name: METADATA_TRANSFORM(1).VALUE
  ordinalPosition: 3
  dataType: VARCHAR2
  parameterMode: IN
- name: METADATA_TRANSFORM(1).OBJECT_TYPE
  ordinalPosition: 4
  dataType: VARCHAR2
  parameterMode: IN
- name: METADATA_TRANSFORM(2).HANDLE
  ordinalPosition: 1
  dataType: NUMBER
  parameterMode: IN
- name: METADATA_TRANSFORM(2).NAME
  ordinalPosition: 2
  dataType: VARCHAR2
  parameterMode: IN
- name: METADATA_TRANSFORM(2).VALUE
  ordinalPosition: 3
  dataType: NUMBER
  parameterMode: IN
- name: METADATA_TRANSFORM(2).OBJECT_TYPE
  ordinalPosition: 4
  dataType: VARCHAR2
  parameterMode: IN
- name: OPEN.OPERATION
  ordinalPosition: 1
  dataType: VARCHAR2
  parameterMode: IN
- name: OPEN.JOB_MODE
  ordinalPosition: 2
  dataType: VARCHAR2
  parameterMode: IN
- name: OPEN.REMOTE_LINK
  ordinalPosition: 3
  dataType: VARCHAR2
  parameterMode: IN
- name: OPEN.JOB_NAME
  ordinalPosition: 4
  dataType: VARCHAR2
  parameterMode: IN
- name: OPEN.VERSION
  ordinalPosition: 5
  dataType: VARCHAR2
  parameterMode: IN
- name: OPEN.COMPRESSION
  ordinalPosition: 6
  dataType: NUMBER
  parameterMode: IN
- name: SET_DEBUG(1).ON_OFF
  ordinalPosition: 1
  dataType: NUMBER
  parameterMode: IN
- name: SET_DEBUG(1).IP_ADDR
  ordinalPosition: 2
  dataType: VARCHAR2
  parameterMode: IN
- name: SET_DEBUG(2).DEBUG_FLAGS
  ordinalPosition: 1
  dataType: BINARY_INTEGER
  parameterMode: IN
- name: SET_DEBUG(2).VERSION_FLAG
  ordinalPosition: 2
  dataType: BINARY_INTEGER
  parameterMode: IN
- name: SET_PARALLEL.HANDLE
  ordinalPosition: 1
  dataType: NUMBER
  parameterMode: IN
- name: SET_PARALLEL.DEGREE
  ordinalPosition: 2
  dataType: NUMBER
  parameterMode: IN
- name: SET_PARAMETER(1).HANDLE
  ordinalPosition: 1
  dataType: NUMBER
  parameterMode: IN
- name: SET_PARAMETER(1).NAME
  ordinalPosition: 2
  dataType: VARCHAR2
  parameterMode: IN
- name: SET_PARAMETER(1).VALUE
  ordinalPosition: 3
  dataType: VARCHAR2
  parameterMode: IN
- name: SET_PARAMETER(2).HANDLE
  ordinalPosition: 1
  dataType: NUMBER
  parameterMode: IN
- name: SET_PARAMETER(2).NAME
  ordinalPosition: 2
  dataType: VARCHAR2
  parameterMode: IN
- name: SET_PARAMETER(2).VALUE
  ordinalPosition: 3
  dataType: NUMBER
  parameterMode: IN
- name: SET_REMOTE_WORKER.WORKER_ID
  ordinalPosition: 1
  dataType: NUMBER
  parameterMode: IN
- name: SETUP_REMOTE_CONTEXT.USER_NAME
  ordinalPosition: 1
  dataType: VARCHAR2
  parameterMode: IN
- name: SETUP_REMOTE_CONTEXT.JOB_NAME
  ordinalPosition: 2
  dataType: VARCHAR2
  parameterMode: IN
- name: SETUP_REMOTE_CONTEXT.VERSION
  ordinalPosition: 3
  dataType: NUMBER
  parameterMode: IN
- name: SETUP_REMOTE_CONTEXT.STATUS_XML
  ordinalPosition: 4
  dataType: VARCHAR2
  parameterMode: IN
- name: SETUP_REMOTE_CONTEXT.STATUS_XML_LEN
  ordinalPosition: 5
  dataType: NUMBER
  parameterMode: IN
- name: SETUP_REMOTE_CONTEXT.MORE
  ordinalPosition: 6
  dataType: NUMBER
  parameterMode: IN
- name: START_JOB.HANDLE
  ordinalPosition: 1
  dataType: NUMBER
  parameterMode: IN
- name: START_JOB.SKIP_CURRENT
  ordinalPosition: 2
  dataType: NUMBER
  parameterMode: IN
- name: START_JOB.ABORT_STEP
  ordinalPosition: 3
  dataType: NUMBER
  parameterMode: IN
- name: START_JOB.CLUSTER_OK
  ordinalPosition: 4
  dataType: NUMBER
  parameterMode: IN
- name: START_JOB.SERVICE_NAME
  ordinalPosition: 5
  dataType: VARCHAR2
  parameterMode: IN
- name: STOP_JOB.HANDLE
  ordinalPosition: 1
  dataType: NUMBER
  parameterMode: IN
- name: STOP_JOB.IMMEDIATE
  ordinalPosition: 2
  dataType: NUMBER
  parameterMode: IN
- name: STOP_JOB.KEEP_MASTER
  ordinalPosition: 3
  dataType: NUMBER
  parameterMode: IN
- name: STOP_JOB.DELAY
  ordinalPosition: 4
  dataType: NUMBER
  parameterMode: IN
- name: TRACE_ENTRY.FACILITY
  ordinalPosition: 1
  dataType: VARCHAR2
  parameterMode: IN
- name: TRACE_ENTRY.MSG
  ordinalPosition: 2
  dataType: VARCHAR2
  parameterMode: IN
- name: WAIT_FOR_JOB.HANDLE
  ordinalPosition: 1
  dataType: NUMBER
  parameterMode: IN
- name: WAIT_FOR_JOB.JOB_STATE
  ordinalPosition: 2
  dataType: VARCHAR2
  parameterMode: OUT
routineDefinition: |-
  PACKAGE dbms_datapump AUTHID CURRENT_USER AS ---------------------------------------------------------------------
  -- Overview
  -- This pkg implements the DBMS_DATAPUMP API, a mechanism to allow users
  -- to move all or parts of a database between databases, superseding
  -- functionality previously associated with the Export and Import utilities
  -- (which will now rely on the dbms_datapump interface). Dbms_datapump will
  -- also support the loading and unloading of data in a proprietary format.
  ---------------------------------------------------------------------
  -- SECURITY
  -- This package is owned by SYS with execute access granted to PUBLIC.
  -- It runs with invokers rights for the most part, i.e., with the security
  -- profile of the caller. Two roles allow users to take full advantage of
  -- the API:
  -- EXP_FULL_DATABASE (only affects Export and Estimate operations) allows:
  --      o Operations outside the scope of a user's schema
  --      o Operations with increased parallelism
  --      o Writes to log and dump files without setting up DIRECTORY objects
  --        to reference their owning directories
  --      o Use of sequential media within a dump file set
  --      o Restarts of previously stopped jobs initiated by another user
  -- IMP_FULL_DATABASE (only affects Import, Network, and Sql_file
  --        operations) allows:
  --      o Operations outside the scope of their schema
  --      o Operations with increased parallelism
  --      o Reads to dump file sets and writes to log files without the use of
  --        DIRECTORY objects
  --      o Use of sequential media within the dump file set
  --      o Restarts of previously stopped jobs initiated by another user
  -- Note that some internal operations will run in a more privileged context.
  --------------------
  --  PUBLIC CONSTANTS
  --
  KU$_STATUS_WIP CONSTANT BINARY_INTEGER: = 1;
  KU$_STATUS_JOB_DESC CONSTANT BINARY_INTEGER: = 2;
  KU$_STATUS_JOB_STATUS CONSTANT BINARY_INTEGER: = 4;
  KU$_STATUS_JOB_ERROR CONSTANT BINARY_INTEGER: = 8;
  KU$_FILE_TYPE_DUMP_FILE CONSTANT BINARY_INTEGER: = 1;
  KU$_FILE_TYPE_BAD_FILE CONSTANT BINARY_INTEGER: = 2;
  KU$_FILE_TYPE_LOG_FILE CONSTANT BINARY_INTEGER: = 3;
  KU$_FILE_TYPE_SQL_FILE CONSTANT BINARY_INTEGER: = 4;
  KU$_DUMPFILE_TYPE_DISK CONSTANT BINARY_INTEGER: = 0;
  KU$_DUMPFILE_TYPE_PIPE CONSTANT BINARY_INTEGER: = 1;
  KU$_DUMPFILE_TYPE_TAPE CONSTANT BINARY_INTEGER: = 2;
  KU$_DUMPFILE_TYPE_TEMPLATE CONSTANT BINARY_INTEGER: = 3;
  KU$_STATUS_VERSION_1 CONSTANT NUMBER: = 1;
  KU$_STATUS_VERSION_2 CONSTANT NUMBER: = 2;
  KU$_STATUS_VERSION_3 CONSTANT NUMBER: = 3;
  KU$_STATUS_VERSION_4 CONSTANT NUMBER: = 4;
  KU$_STATUS_VERSION CONSTANT NUMBER: = KU$_STATUS_VERSION_4;
  KU$_JOB_VIEW_ALL CONSTANT NUMBER: = 0;
  KU$_JOB_VIEW_TTS_TABLESPACES CONSTANT NUMBER: = 1;
  KU$_JOB_VIEW_ENCCOL_TABLES CONSTANT NUMBER: = 2;
  KU$_JOB_COMPLETE CONSTANT NUMBER: = 1;
  KU$_JOB_COMPLETE_ERRORS CONSTANT NUMBER: = 2;
  KU$_JOB_STOPPED CONSTANT NUMBER: = 3;
  KU$_JOB_ABORTED CONSTANT NUMBER: = 4;
  --
  -- Items codes for entry in a dump file info table (of type ku$_dumpfile_info).
  --
  -- NOTE: For each constant defined here there is a corresponding constant
  --       defined in kupf.h named KUPF_DFINFO_xxx_IDX where xxx is VERSION,
  --       MASTER_PRESENT, GUID, etc. Any changes to the constants defined
  --       *MUST* be reflected to those defined in kupf.h
  --
  KU$_DFHDR_FILE_VERSION CONSTANT NUMBER: = 1;
  KU$_DFHDR_MASTER_PRESENT CONSTANT NUMBER: = 2;
  KU$_DFHDR_GUID CONSTANT NUMBER: = 3;
  KU$_DFHDR_FILE_NUMBER CONSTANT NUMBER: = 4;
  KU$_DFHDR_CHARSET_ID CONSTANT NUMBER: = 5;
  KU$_DFHDR_CREATION_DATE CONSTANT NUMBER: = 6;
  KU$_DFHDR_FLAGS CONSTANT NUMBER: = 7;
  KU$_DFHDR_JOB_NAME CONSTANT NUMBER: = 8;
  KU$_DFHDR_PLATFORM CONSTANT NUMBER: = 9;
  KU$_DFHDR_INSTANCE CONSTANT NUMBER: = 10;
  KU$_DFHDR_LANGUAGE CONSTANT NUMBER: = 11;
  KU$_DFHDR_BLOCKSIZE CONSTANT NUMBER: = 12;
  KU$_DFHDR_DIRPATH CONSTANT NUMBER: = 13;
  KU$_DFHDR_METADATA_COMPRESSED CONSTANT NUMBER: = 14;
  KU$_DFHDR_DB_VERSION CONSTANT NUMBER: = 15;
  KU$_DFHDR_MASTER_PIECE_COUNT CONSTANT NUMBER: = 16;
  KU$_DFHDR_MASTER_PIECE_NUMBER CONSTANT NUMBER: = 17;
  KU$_DFHDR_DATA_COMPRESSED CONSTANT NUMBER: = 18;
  KU$_DFHDR_METADATA_ENCRYPTED CONSTANT NUMBER: = 19;
  KU$_DFHDR_DATA_ENCRYPTED CONSTANT NUMBER: = 20;
  KU$_DFHDR_COLUMNS_ENCRYPTED CONSTANT NUMBER: = 21;
  --
  -- Item codes KU$_DFHDR_ENCPWD_MODE and KU$_DFHDR_ENCPWD_MODE_xxx
  -- are obsolescent and will be removed in a future version. Instead,
  -- KU$_DFHDR_ENCRYPTION_MODE and KU$_DFHDR_ENCMODE_xxx should be used.
  --
  KU$_DFHDR_ENCPWD_MODE CONSTANT NUMBER: = 22;
  KU$_DFHDR_ENCPWD_MODE_UNKNOWN CONSTANT NUMBER: = 1;
  KU$_DFHDR_ENCPWD_MODE_NONE CONSTANT NUMBER: = 2;
  KU$_DFHDR_ENCPWD_MODE_PASSWORD CONSTANT NUMBER: = 3;
  KU$_DFHDR_ENCPWD_MODE_DUAL CONSTANT NUMBER: = 4;
  KU$_DFHDR_ENCPWD_MODE_TRANS CONSTANT NUMBER: = 5;
  --
  -- KU$_DFHDR_ENCMODE_xxx are values that can be returned
  -- for item code KU$_DFHDR_ENCRYPTION_MODE.
  --
  KU$_DFHDR_ENCRYPTION_MODE CONSTANT NUMBER: = 22;
  KU$_DFHDR_ENCMODE_UNKNOWN CONSTANT NUMBER: = 1;
  KU$_DFHDR_ENCMODE_NONE CONSTANT NUMBER: = 2;
  KU$_DFHDR_ENCMODE_PASSWORD CONSTANT NUMBER: = 3;
  KU$_DFHDR_ENCMODE_DUAL CONSTANT NUMBER: = 4;
  KU$_DFHDR_ENCMODE_TRANS CONSTANT NUMBER: = 5;
  --
  -- KU$_DFHDR_CMPALG_xxx are values that can be returned
  -- for item code KU$_DFHDR_COMPRESSION_ALG.
  --
  KU$_DFHDR_COMPRESSION_ALG CONSTANT NUMBER: = 23;
  KU$_DFHDR_CMPALG_UNKNOWN CONSTANT NUMBER: = 1;
  KU$_DFHDR_CMPALG_NONE CONSTANT NUMBER: = 2;
  KU$_DFHDR_CMPALG_BASIC CONSTANT NUMBER: = 3;
  KU$_DFHDR_CMPALG_LOW CONSTANT NUMBER: = 4;
  KU$_DFHDR_CMPALG_MEDIUM CONSTANT NUMBER: = 5;
  KU$_DFHDR_CMPALG_HIGH CONSTANT NUMBER: = 6;
  KU$_DFHDR_MAX_ITEM_CODE CONSTANT NUMBER: = 23;
  KU$_COMPRESS_NONE CONSTANT NUMBER: = 1;
  KU$_COMPRESS_METADATA CONSTANT NUMBER: = 2;
  -- Bitmask defs used in DATA_OPTIONS parameter. Values above 1048576 are
  -- reserved for internal use.
  KU$_DATAOPT_SKIP_CONST_ERR CONSTANT NUMBER: = 1;
  KU$_DATAOPT_XMLTYPE_CLOB CONSTANT NUMBER: = 2;
  KU$_DATAOPT_NOTYPE_EVOL CONSTANT NUMBER: = 4;
  KU$_DATAOPT_DISABL_APPEND_HINT CONSTANT NUMBER: = 8;
  KU$_DATAOPT_REJECT_ROWS_REPCHR CONSTANT NUMBER: = 16;
  -- Bitmask defs for the flags field of dictionary table impcalloutreg$
  -- See dtools.bsq for detailed descriptions
  KU$_ICRFLAGS_IS_EXPR CONSTANT NUMBER: = 1;
  KU$_ICRFLAGS_EARLY_IMPORT CONSTANT NUMBER: = 2;
  KU$_ICRFLAGS_GET_DEPENDENTS CONSTANT NUMBER: = 4;
  KU$_ICRFLAGS_EXCLUDE CONSTANT NUMBER: = 8;
  KU$_ICRFLAGS_XDB_NO_TTS CONSTANT NUMBER: = 16;
  -- Values for 'prepost' in import callouts
  KU$_ICRPP_PREIMPORT CONSTANT NUMBER: = 0;
  KU$_ICRPP_EARLY CONSTANT NUMBER: = 2;
  KU$_ICRPP_FINAL CONSTANT NUMBER: = 1;
  -- Bitmask defs for flags field of data_remap
  KU$_DATA_REMAP_WITH_ROWID CONSTANT NUMBER: = 1;
  -------------
  -- EXCEPTIONS
  --      The following exceptions can be generated by the DBMS_DATAPUMP API:
  -- INVALID_ARGVAL, PRIVILEGE_ERROR, INVALID_OPERATION,
  -- OBJECT_NOT_FOUND, INVALID_HANDLE, INVALID_STATE, INCONSISTENT_ARGS,
  -- JOB_EXISTS, NO_SUCH_JOB, INVALID_VALUE, SUCCESS_WITH_INFO
  --
  invalid_argval
  EXCEPTION;
  -- OK
    PRAGMA EXCEPTION_INIT(invalid_argval, -39001);
  invalid_argval_num NUMBER: = -39001;
  -- "Invalid argument value"
    -- *Cause:  The user specified API parameters were of the wrong type or
    --          value range.  Subsequent messages supplied by
    --          DBMS_DATAPUMP.GET_STATUS will further describe the error.
    -- *Action: Correct the bad argument and retry the API.
    invalid_operation
  EXCEPTION;
  PRAGMA EXCEPTION_INIT(invalid_operation, -39002);
  invalid_operation_num NUMBER: = -39002;
  -- "invalid operation"
    -- *Cause:  The current API cannot be executed because of inconsistencies
    --          between the API and the current definition of the job.
    --          Subsequent messages supplied by DBMS_DATAPUMP.GET_STATUS
    --          will further describe the error.
    -- *Action: Modify the API call to be consistent with the current job or
    --          redefine the job in a manner that will support the specified API.
    inconsistent_args
  EXCEPTION;
  -- OK
    PRAGMA EXCEPTION_INIT(inconsistent_args, -39005);
  inconsistent_args_num NUMBER: = -39005;
  -- "inconsistent arguments"
    -- *Cause:  The current API cannot be executed because of inconsistencies
    --          between arguments of the API call.
    --          Subsequent messages supplied by DBMS_DATAPUMP.GET_STATUS
    --          will further describe the error.
    -- *Action: Modify the API call to be consistent with itself.
    privilege_error
  EXCEPTION;
  PRAGMA EXCEPTION_INIT(privilege_error, -31631);
  privilege_error_num NUMBER: = -31631;
  -- "privileges are required"
    -- *Cause:  The necessary privileges are not available for operations such
    --          as: restarting a job on behalf of another owner, using a device
    --          as a member of the dump file set, or ommiting a directory
    --          object associated with any of the various output files.
    -- *Action: Select a different job to restart, try a different operation, or
    --          contact a database administrator to acquire the needed privileges.
    invalid_handle
  EXCEPTION;
  PRAGMA EXCEPTION_INIT(invalid_handle, -31623);
  invalid_handle_num NUMBER: = -31623;
  -- "The current session is not attached to the specified handle"
    -- *Cause:  User specified an incorrect handle for a job.
    -- *Action: Make sure handle was returned by DBMS_DATAPUMP.OPEN call.
    invalid_state
  EXCEPTION;
  PRAGMA EXCEPTION_INIT(invalid_state, -39004);
  invalid_state_num NUMBER: = -39004;
  -- "invalid state"
    -- *Cause:  The state of the job precludes the execution of the API.
    -- *Action: Rerun the job to specify the API when the job is an appropriate
    --          state.
    job_exists
  EXCEPTION;
  PRAGMA EXCEPTION_INIT(job_exists, -31634);
  job_exists_num NUMBER: = -31634;
  -- "job already exists"
    -- *Cause:  Job creation or restart failed because a job having the selected
    --          name is currently executing.  This also generally indicates that
    --          a Master Table with that job name exists in the user schema.
    -- *Action: Select a different job name, or stop the currently executing job
    --          and re-try the operation (may require a DROP on the Master Table).
    no_such_job
  EXCEPTION;
  PRAGMA EXCEPTION_INIT(no_such_job, -31626);
  no_such_job_num NUMBER: = -31626;
  -- "job does not exist"
    -- *Cause:  A invalid reference to a job which is no longer executing,
    --          is not executing on the instance where the operation was
    --          attempted, or that does not have a valid Master Table.
    --          Refer to the secondary error messages that follow this one for
    --          clarification concerning the problems with the Master Table.
    -- *Action: Start a new job, or attach to an existing job that has a
    --          valid Master Table.
    internal_error
  EXCEPTION;
  PRAGMA EXCEPTION_INIT(internal_error, -39006);
  internal_error_num NUMBER: = -39006;
  -- "internal error"
    -- *Cause:  An unexpected error occurred while processing a DataPump job.
    --          Subsequent messages supplied by DBMS_DATAPUMP.GET_STATUS
    --          will further describe the error.
    -- *Action: Contact Oracle Support.
    success_with_info
  EXCEPTION;
  PRAGMA EXCEPTION_INIT(success_with_info, -31627);
  success_with_info_num NUMBER: = -31627;
  -- "API call succeeded but more information is available."
    -- *Cause: User specified job parameters that yielded informational messages.
    -- *Action: Call DBMS_DATAPUMP.GET_STATUS to retrieve additional information.
    no_dumpfile_info
  EXCEPTION;
  PRAGMA EXCEPTION_INIT(no_dumpfile_info, -39211);
  no_dumpfile_info_num NUMBER: = -39211;
  -- "Unable to retrieve dumpfile information as specified."
    -- *Cause:  User specified an invalid or inaccessible file with the specified
    --          filename and directory object.
    -- *Action: Retry the operation with a valid directory object and filename.
    warning_dv_noencrypt
  EXCEPTION;
  PRAGMA EXCEPTION_INIT(warning_dv_noencrypt, -39327);
  warning_dv_noencrypt_num NUMBER: = -39327;
  -- "Database Vault data is being stored unencrypted in dump file set."
    -- *Cause:  No encryption was specified for an export job that involved data
    --          from a Database Vault Realm.
    -- *Action: No specific user action is required.  This is only a warning that
    --          secure data may be readable from within the dump file set.
    ---------------------------
    -- PROCEDURES AND FUNCTIONS
    ---------------------------
    --
    -- ADD_DEVICE: Adds a sequential device to the dump file set for Export,
    --             Import, or Sql_file operations.
    -- PARAMETERS:
    --      handle     - Handle of the job (returned by OPEN)
    --      devicename - Name of the device being added.
    --      volumesize - Backing store capacity for the device.
    --
    -- RETURNS:
    --      None
    -- EXCEPTIONS:
    --      INVALID_HANDLE    - The current session is not attached to this handle
    --      INVALID_ARGVAL    - A NULL or invalid value was supplied for an input
    --                          parameter.
    --      PRIVILEGE_ERROR   - User didn't have EXP_FULL_DATABASE or
    --                          IMP_FULL_DATABASE role
    --      INVALID_OPERATION - The file was specified for a Network or Estimate
    --                          operation, or the file was specified for an
    --                          executing import or sql_file operation.
    --      SUCCESS_WITH_INFO - API succeeded but further information available
    --                          through the get_status API
    --      NO_SUCH_JOB       - The job handle is no longer valid or job no longer
    --                          exists
    PROCEDURE add_device (
      handle IN NUMBER,
      devicename IN VARCHAR2,
      volumesize IN VARCHAR2 DEFAULT NULL
    );
  -- ADD_FILE: Adds a file to the dump file set for Export, Import, or Sql_file
    --           operations as well as log files, bad files, and sql files.
    -- PARAMETERS:
    --      handle    - Handle of the job (returned by OPEN)
    --      filename  - Name of the file being added. This must be a simple
    --                  filename with no directory path information if the
    --                  directory parameter is specified. Filename can contain
    --                  substitution characters to use this name as a template to
    --                  create multiple files.
    --      directory - Name of the directory object within the database that is
    --                  used to locate the filename. Users with
    --                  IMP_FULL_DATABASE or EXP_FULL_DATABASE roles can
    --                  specify the directory path in the filename, but other
    --                  users must specify this parameter.
    --      filesize  - Size of the file being added. It may be specified as number
    --                  of bytes, number of kilobytes (followed by 'K'), number of
    --                  megabytes (followed by 'M'), number of gigabytes
    --                  (followed by 'G') or the number of terabytes (followed
    --                  by 'T'). This parameter is ignored for import and
    --                  sql_file operations. On export operations, no more than
    --                  the specified number of bytes will be written to the file,
    --                  and if there is insufficient space on the device, the
    --                  operation will fail. If not specified on export, the
    --                  default will be unlimited size with allocations in 50 Mbyte
    --                  increments. The minimum allowed filesize is 10 times the
    --                  default block size for the file system.
    --      filetype  - Type of file being added to the job. This numeric constant
    --                  indicates whether it is a dump file, log file, bad file,
    --                  or sql file being added to the job.
    --     reusefile  - Flag indicating whether or not an existing dumpfile
    --                  should be reused (i.e., overwritten) during an export
    --                  operation. Valid values are:
    --                    NULL - use the default behavior for the file type:
    --                           for dump files, the default is do not reuse;
    --                           for log and sql files, the default is reuse.
    --                       0 - do not reuse (only meaningful for dump files).
    --                       1 - reuse (only meaningful for dump files).
    --
    -- RETURNS:
    --      None
    -- EXCEPTIONS:
    --      INVALID_HANDLE    - The current session is not attached to this handle
    --      INVALID_ARGVAL    - A NULL or invalid value was supplied for an input
    --                          parameter.
    --      INVALID_STATE     - The current job state does not allow for the
    --                          addition of files to the job (only for SQL and
    --                          LOG files)
    --      INVALID_OPERATION - The file was specified for a Network or Estimate
    --                          operation, or the file was specified for an
    --                          executing import or sql_file operation.
    --      SUCCESS_WITH_INFO - API succeeded but further information available
    --                          through the get_status API
    --      NO_SUCH_JOB       - The job handle is no longer valid or job no longer
    --                          exists
    PROCEDURE add_file (
      handle IN NUMBER,
      filename IN VARCHAR2,
      directory IN VARCHAR2 DEFAULT NULL,
      filesize IN VARCHAR2 DEFAULT NULL,
      filetype IN NUMBER DEFAULT KU$_FILE_TYPE_DUMP_FILE,
      reusefile IN NUMBER DEFAULT NULL
    );
  -- ATTACH: Acquire access to an active or stopped job
    --
    -- PARAMETERS:
    --      job_name  - Identifies the particular job or operation. It will default
    --                  to the name of a job owned by the user specified by
    --                  job_owner if that user has only one job in the defining,
    --                  executing, idling, waiting, or completing states.
    --      job_owner - The user that started the job. If NULL, it defaults to the
    --                  owner of the current session. To specify a different
    --                  job_owner (than themselves), users must have
    --                  IMP_FULL_DATABASE or EXP_FULL_DATABASE roles
    --                  (depending on the operation)
    --
    -- RETURNS:
    --      A handle to be used in subsequent calls to all other DBMS_DATAPUMP
    --      operations.
    -- EXCEPTIONS:
    --      INVALID_ARGVAL    - A NULL or invalid value was supplied for an input
    --                          parameter.
    --      INVALID_OPERATION - This operation can not be restarted
    --      SUCCESS_WITH_INFO - API succeeded but further information available
    --                          through the get_status API
    --      NO_SUCH_JOB       - The job handle is no longer valid or job no longer
    --                          exists
    FUNCTION attach (
      job_name IN VARCHAR2 DEFAULT NULL,
      job_owner IN VARCHAR2 DEFAULT NULL
    ) RETURN NUMBER;
  -- DATA_FILTER: Filter data using subqueries or excluding all user data
    --
    -- PARAMETERS:
    --      handle      - Identifies the particular job or operation (from OPEN)
    --      name        - The filter name or type to use (see documentation)
    --      value       - Filter details
    --      table_name  - Table name for applying the filter. Will default to all
    --                    all tables if not specified.
    --      schema_name - Name of the schema owning the table to apply the data
    --                    filter. Null implies all schemas in the job.
    --
    -- RETURNS:
    --      NONE
    -- EXCEPTIONS:
    --      INVALID_HANDLE    - The current session is not attached to this handle
    --      INVALID_ARGVAL    - A NULL or invalid value was supplied for an input
    --                          parameter.
    --      PRIVILEGE_ERROR   - The specified operation requires privileges
    --      INVALID_STATE     - The job is not in the defining state
    --      INCONSISTENT_ARGS - The datatype of value does not match the filter
    --                          name
    --      SUCCESS_WITH_INFO - API succeeded but further information available
    --                          through the get_status API
    --      NO_SUCH_JOB       - The job handle is no longer valid or job no longer
    --                          exists
    PROCEDURE data_filter (
      handle IN NUMBER,
      name IN VARCHAR2,
      value IN NUMBER,
      table_name IN VARCHAR2 DEFAULT NULL,
      schema_name IN VARCHAR2 DEFAULT NULL
    );
  PROCEDURE data_filter (
      handle IN NUMBER,
      name IN VARCHAR2,
      value IN CLOB,
      table_name IN VARCHAR2 DEFAULT NULL,
      schema_name IN VARCHAR2 DEFAULT NULL
    );
  PROCEDURE data_filter (
      handle IN NUMBER,
      name IN VARCHAR2,
      value IN VARCHAR2,
      table_name IN VARCHAR2 DEFAULT NULL,
      schema_name IN VARCHAR2 DEFAULT NULL
    );
  -- DATA_REMAP: Modify the values of data in user tables
    --
    -- PARAMETERS:
    --      handle      - Identifies the particular job or operation (from OPEN)
    --      name        - The type of data remapping to be performed
    --      table_name  - Table name for applying the remap.
    --      column      - Column name for where the data needs to be remapped
    --      function    - Function used to remap the column data.
    --      schema      - Name of the schema owning the table to apply the data
    --                    remap. Null implies all schemas in the job.
    --      flags       - flags to modify data remap.
    --                    current flags are: with_rowid - send in rowid to function
    --
    -- RETURNS:
    --      NONE
    -- EXCEPTIONS:
    --      INVALID_HANDLE    - The current session is not attached to this handle
    --      INVALID_ARGVAL    - A NULL or invalid value was supplied for an input
    --                          parameter.
    --      NO_SUCH_JOB       - The job handle is no longer valid or job no longer
    --                          exists
    PROCEDURE data_remap (
      handle IN NUMBER,
      name IN VARCHAR2,
      table_name IN VARCHAR2,
      column IN VARCHAR2,
      function IN VARCHAR2,
      schema IN VARCHAR2 DEFAULT NULL,
      remap_flags IN NUMBER DEFAULT 0
    );
  -- DETACH: Detach current session (and handle) from job
    --
    -- PARAMETERS:
    --      handle  - Identifies the particular job or operation (from OPEN/ATTACH)
    --
    -- RETURNS:
    --      NONE
    -- EXCEPTIONS:
    --      INVALID_HANDLE    - The current session is not attached to this handle
    --      SUCCESS_WITH_INFO - API succeeded but further information available
    --                          through the get_status API
    --      NO_SUCH_JOB       - The job handle is no longer valid or job no longer
    --                          exists
    PROCEDURE detach (
      handle IN NUMBER
    );
  -- GET_DUMPFILE_INFO: Analyze specified file and return dumpfile information
    --
    -- PARAMETERS:
    --      filename   - Name of the file being added. This must be a simple
    --                   filename with no directory path information.
    --      directory  - Name of the directory object within the database that is
    --                   used to locate the filename.
    --      info_table - (OUT) The ku$_dumpfile_info table to be
    --                   populated with dumpfile header information.
    --      filetype   - (OUT) 0 => Unknown file type
    --                         1 => Data Pump dumpfile
    --                         2 => Classic Export dumpfile
    -- RETURNS:
    --      NONE
    --
    -- EXCEPTIONS:
    --      Fatal exceptions raised - all others eaten
    PROCEDURE get_dumpfile_info (
      filename IN VARCHAR2,
      directory IN VARCHAR2,
      info_table OUT ku$_dumpfile_info,
      filetype OUT NUMBER
    );
  -- GET_STATUS: Get status of job (for monitoring and control)
    --
    -- PARAMETERS:
    --      handle      - Identifies the particular job (from OPEN/ATTACH)
    --      mask        - Bit mask to specify the information to be returned:
    --                      Bit 0  - Retrieve work in progress (wip) information
    --                      Bit 1  - Retrieve job complete description information
    --                      Bit 2  - Retrieve detailed job and per-worker progress
    --                               and status (NOTE: Retrieving the job status
    --                               and checking the job state for 'COMPLETED' is
    --                               the proper mechanism for detecting that a job
    --                               has completed successfully. Once the job has
    --                               entered this state, subsequent calls will
    --                               likely result in an invalid_handle exception)
    --                      Bit 3  - Retrieve error packet/log entry information
    --      timeout    - Max seconds to wait if no pending status queue entries.
    --                   Specifying zero or null results in an immediate return
    --                   and -1 will wait indefinitely. The timeout will be
    --                   ignored when the job is in the 'COMPLETING' or
    --                   'COMPLETED' states.
    --      job_state  - (OUT) Current job state of this Data Pump job (newer
    --                   procedural interface only)
    --      status     - (OUT) ku$_Status object with requested information in the
    --                   newer procedural interface only
    --
    -- RETURNS:
    --      ku$_Status object with requested information in the initial functional
    --      interface only (to be deprecated)
    --
    -- EXCEPTIONS:
    --      INVALID_HANDLE    - The current session is not attached to this handle
    --      SUCCESS_WITH_INFO - API succeeded but further information available
    --                          through the get_status API
    --      NO_SUCH_JOB       - The job handle is no longer valid or job no longer
    --                          exists
    FUNCTION get_status (
      handle IN NUMBER,
      mask IN INTEGER,
      timeout IN NUMBER DEFAULT NULL
    ) RETURN ku$_Status;
  PROCEDURE get_status (
      handle IN NUMBER,
      mask IN INTEGER,
      timeout IN NUMBER DEFAULT NULL,
      job_state OUT VARCHAR2,
      status OUT ku$_Status1010
    );
  PROCEDURE get_status (
      handle IN NUMBER,
      mask IN INTEGER,
      timeout IN NUMBER DEFAULT NULL,
      job_state OUT VARCHAR2,
      status OUT ku$_Status1020
    );
  PROCEDURE get_status (
      handle IN NUMBER,
      mask IN INTEGER,
      timeout IN NUMBER DEFAULT NULL,
      job_state OUT VARCHAR2,
      status OUT ku$_Status1120
    );
  PROCEDURE get_status (
      handle IN NUMBER,
      mask IN INTEGER,
      timeout IN NUMBER DEFAULT NULL,
      job_state OUT VARCHAR2,
      status OUT ku$_Status1210
    );
  -- LOG_ENTRY: Add entry to log file and broadcast to all get_status callers
    --
    -- PARAMETERS:
    --      handle        - Identifies the particular job (from OPEN/ATTACH)
    --      message       - Text to be added to the log file
    --      log_file_only - Specified text to be written to the log file only and
    --                      not to the status queues like other log messages
    --
    -- RETURNS:
    --      NONE
    --
    -- EXCEPTIONS:
    --      INVALID_HANDLE    - The current session is not attached to this handle
    --      SUCCESS_WITH_INFO - API succeeded but further information available
    --                          through the get_status API
    --      NO_SUCH_JOB       - The job handle is no longer valid or job no longer
    --                          exists
    PROCEDURE log_entry (
      handle IN NUMBER,
      message IN VARCHAR2,
      log_file_only IN NUMBER DEFAULT 0
    );
  -- METADATA_FILTER: Applies transformations to objects' DDL during import,
    --                  network, and sql_file operations
    --
    -- PARAMETERS:
    --      handle      - Identifies the particular job or operation (from OPEN)
    --      name        - Name of the metadata filter (see documentation).
    --      value       - Text expression for the filter in the name parameter
    --      object_path - The object path to which the filter applies (default=all
    --                    objects).
    --      object_type - For backward compatibility, can be used to specify the
    --                    object path (see above)
    --
    -- RETURNS:
    --      NONE
    -- EXCEPTIONS:
    --      INVALID_HANDLE    - The current session is not attached to this handle
    --      INVALID_ARGVAL    - A NULL or invalid value was supplied for an input
    --                          parameter.
    --      INVALID_STATE     - The job is not in the defining state
    --      INCONSISTENT_ARGS - The value specification does not match the metadata
    --                          filter name
    --      SUCCESS_WITH_INFO - API succeeded but further information available
    --                          through the get_status API
    --      NO_SUCH_JOB       - The job handle is no longer valid or job no longer
    --                          exists
    PROCEDURE metadata_filter (
      handle IN NUMBER,
      name IN VARCHAR2,
      value IN VARCHAR2,
      object_path IN VARCHAR2 DEFAULT NULL,
      object_type IN VARCHAR2 DEFAULT NULL
    );
  PROCEDURE metadata_filter (
      handle IN NUMBER,
      name IN VARCHAR2,
      value IN CLOB,
      object_path IN VARCHAR2 DEFAULT NULL,
      object_type IN VARCHAR2 DEFAULT NULL
    );
  -- METADATA_TRANSFORM: Allows transformations applied to objects during jobs
    --
    -- PARAMETERS:
    --      handle      - Identifies the particular job or operation (from OPEN)
    --      name        - Name of the transformation (see documentation).
    --      value       - The value of the parameter for the transform
    --      object_type - The object type to which the transform applies
    --                    (default=all objects)
    --
    -- RETURNS:
    --      NONE
    -- EXCEPTIONS:
    --      INVALID_HANDLE    - The current session is not attached to this handle
    --      INVALID_ARGVAL    - A NULL or invalid value was supplied for an input
    --                          parameter.
    --      INVALID_STATE     - The job is not in the defining state or operation
    --                          is either export or estimate which don't support
    --                          transforms.
    --      INVALID_OPERATION - Transforms not permitted for this operation
    --      INCONSISTENT_ARGS - The value specification does not match the metadata
    --                          transform name
    --      SUCCESS_WITH_INFO - API succeeded but further information available
    --                          through the get_status API
    --      NO_SUCH_JOB       - The job handle is no longer valid or job no longer
    --                          exists
    PROCEDURE metadata_transform (
      handle IN NUMBER,
      name IN VARCHAR2,
      value IN VARCHAR2,
      object_type IN VARCHAR2 DEFAULT NULL
    );
  PROCEDURE metadata_transform (
      handle IN NUMBER,
      name IN VARCHAR2,
      value IN NUMBER,
      object_type IN VARCHAR2 DEFAULT NULL
    );
  -- METADATA_REMAP: Allows remappings applied to objects during jobs
    --
    -- PARAMETERS:
    --      handle      - Identifies the particular job or operation (from OPEN)
    --      name        - Name of the mapping to occur (see documentation).
    --      old_value   - Previous value to reset to new value (value parameter)
    --      value       - The value of the parameter for the mapping
    --      object_type - The object type to which the mapping applies (default=all
    --                    objects)
    --
    -- RETURNS:
    --      NONE
    -- EXCEPTIONS:
    --      INVALID_HANDLE    - The current session is not attached to this handle
    --      INVALID_ARGVAL    - A NULL or invalid value was supplied for an input
    --                          parameter.
    --      INVALID_STATE     - The job is not in the defining state or operation
    --                          is either export or estimate which don't support
    --                          transforms.
    --      INVALID_OPERATION - Remaps not permitted for this operation
    --      INCONSISTENT_ARGS - The value specification does not match the metadata
    --                          transform name
    --      SUCCESS_WITH_INFO - API succeeded but further information available
    --                          through the get_status API
    --      NO_SUCH_JOB       - The job handle is no longer valid or job no longer
    --                          exists
    PROCEDURE metadata_remap (
      handle IN NUMBER,
      name IN VARCHAR2,
      old_value IN VARCHAR2,
      value IN VARCHAR2,
      object_type IN VARCHAR2 DEFAULT NULL
    );
  -- OPEN: Create a new DataPump job/operation
    --
    -- PARAMETERS:
    --      operation       - The type of operation to be performed (EXPORT,
    --                        IMPORT, SQL_FILE)
    --      job_mode        - Operation mode (FULL, SCHEMA, TABLE, TABLESPACE,
    --                        TRANSPORTABLE)
    --      remote_link     - Link to source database to be used for network
    --                        operations.
    --      job_name        - Name of the job, implicitly qualified by the schema
    --                        and must be unique to that schema
    --      version         - Version of the database objects to be extracted (for
    --                        export, estimate, and network only). Possible values
    --                        are COMPATIBLE (the default), LATEST, or a specific
    --                        database version.
    --      compression     - Compression to use job-wide on export
    --
    -- RETURNS:
    --      A handle to be used in all subsequent calls (except ATTACH)
    --
    -- EXCEPTIONS:
    --      INVALID_ARGVAL    - A NULL or invalid value was supplied for an input
    --                          parameter.
    --      JOB_EXISTS        - A table having the name job_name already exists.
    --      PRIVILEGE_ERROR   - User doesn't have the privilege to create the
    --                          specified master table
    --      INTERNAL_ERROR    - There was an internal error trying to create the
    --                          DataPump job as specified
    --      SUCCESS_WITH_INFO - API succeeded but further information available
    --                          through the get_status API
    --      NO_SUCH_JOB       - The job handle is no longer valid or job no longer
    --                          exists
    FUNCTION open (
      operation IN VARCHAR2,
      job_mode IN VARCHAR2,
      remote_link IN VARCHAR2 DEFAULT NULL,
      job_name IN VARCHAR2 DEFAULT NULL,
      version IN VARCHAR2 DEFAULT 'COMPATIBLE',
      compression IN NUMBER DEFAULT KU$_COMPRESS_METADATA
    ) RETURN NUMBER;
  -- SET_PARALLEL: Throttle the degree of parallelism within a job
    --
    -- PARAMETERS:
    --      handle  - Identifies the particular job or operation (from OPEN/ATTACH)
    --      degree  - Max number of worker processes that can be used for the job
    --
    -- RETURNS:
    --      NONE
    --
    -- EXCEPTIONS:
    --      INVALID_HANDLE    - The current session is not attached to this handle
    --      INVALID_ARGVAL    - A NULL or invalid value was supplied for an input
    --                          parameter.
    --      INVALID_OPERATION - Changing the degree of parallelism is not permitted
    --                          for this operation
    --      SUCCESS_WITH_INFO - API succeeded but further information available
    --                          through the get_status API
    --      NO_SUCH_JOB       - The job handle is no longer valid or job no longer
    --                          exists
    PROCEDURE set_parallel (
      handle IN NUMBER,
      degree IN NUMBER
    );
  -- SET_PARAMETER: Specify a variety of processing options for a particular job
    --
    -- PARAMETERS:
    --      handle  - Identifies the particular job or operation (from OPEN/ATTACH)
    --      name    - Parameter name (see documentation).
    --      value   - Value for this parameter
    --
    -- RETURNS:
    --      NONE
    --
    -- EXCEPTIONS:
    --      INVALID_HANDLE    - The current session is not attached to this handle
    --      INVALID_ARGVAL    - A NULL or invalid value was supplied for an input
    --                          parameter.
    --      INVALID_STATE     - Job must be in the defining state
    --      INCONSISTENT_ARGS - Datatype of value inconsistent with parameter type
    --      INVALID_OPERATION - The specified parameter is not allowed for the
    --                          current operation
    --      PRIVILEGE_ERROR   - The specified parameter requires privileges
    --      SUCCESS_WITH_INFO - API succeeded but further information available
    --                          through the get_status API
    --      NO_SUCH_JOB       - The job handle is no longer valid or job no longer
    --                          exists
    PROCEDURE set_parameter (
      handle IN NUMBER,
      name IN VARCHAR2,
      value IN VARCHAR2
    );
  PROCEDURE set_parameter (
      handle IN NUMBER,
      name IN VARCHAR2,
      value IN NUMBER
    );
  -- START_JOB: Start or restart a job
    --
    -- PARAMETERS:
    --      handle       - Identifies the particular job or operation (from
    --                     OPEN/ATTACH)
    --      skip_current - If set (on a restart only - ignored on initial start),
    --                     will cause incomplete actions from a previous start to
    --                     be skipped. Default is false.
    --      abort_step   - For testing only
    --      cluster_ok   - If =0, all workers are started in the current intance.
    --                     Otherwise, workers are started on instances usable by
    --                     the job.
    --      service_name - If specified, indicates a service name used to constain
    --                     the job to specific instances or to a specific resource
    --                     group.
    --
    -- RETURNS:
    --      NONE
    --
    -- EXCEPTIONS:
    --      INVALID_HANDLE    - The current session is not attached to this handle
    --      INVALID_STATE     - Job can't be started due to insufficient info
    --      INVALID_OPERATION - The operation as defined has insufficient or
    --                          conflicting attributes and can not be started
    --      SUCCESS_WITH_INFO - API succeeded but further information available
    --                          through the get_status API
    --      NO_SUCH_JOB       - The job handle is no longer valid or job no longer
    --                          exists
    PROCEDURE start_job (
      handle IN NUMBER,
      skip_current IN NUMBER DEFAULT 0,
      abort_step IN NUMBER DEFAULT 0,
      cluster_ok IN NUMBER DEFAULT 1,
      service_name IN VARCHAR2 DEFAULT NULL
    );
  -- STOP_JOB: Terminate a job while preserving its state
    --
    -- PARAMETERS:
    --      handle      - Identifies the particular job or operation (from
    --                    OPEN/ATTACH). This handle is detached on successful
    --                    completion of this call.
    --      immediate   - If true, worker processes are aborted immediately instead
    --                    of being allowed to complete their current work items.
    --                    This halts the job more rapidly at the expense of having
    --                    to rerun parts of the job on a restart.
    --      keep_master - If non-zero, the master table is retained when the job is
    --                    stopped. If zero, the master table is dropped when the
    --                    job is stopped. If null, retention is based on the
    --                    KEEP_MASTER parameter setting.
    --      delay       - Number of seconds that should be waited until other
    --                    attached sessions are forcibly detached. The delay
    --                    allows other sessions attached to the job to be notified
    --                    that a stop has been performed. If delay=0 is specified,
    --                    other attached sessions will find their handles are
    --                    invalid at their next calls to the datapump API.
    --
    -- RETURNS:
    --      NONE
    --
    -- EXCEPTIONS:
    --      INVALID_HANDLE    - The current session is not attached to this handle
    --      INVALID_OPERATION - This operation can not be stopped
    --      SUCCESS_WITH_INFO - API succeeded but further information available
    --                          through the get_status API
    --      NO_SUCH_JOB       - The job handle is no longer valid or job no longer
    --                          exists
    PROCEDURE stop_job (
      handle IN NUMBER,
      immediate IN NUMBER DEFAULT 0,
      keep_master IN NUMBER DEFAULT NULL,
      delay IN NUMBER DEFAULT 60
    );
  -- WAIT_FOR_JOB: Wait for job to complete and then return
    --
    -- PARAMETERS:
    --      handle      - Identifies the particular job or operation (from
    --                    OPEN/ATTACH). This handle is detached on successful
    --                    completion of this call.
    --      job_state   - (OUT) The job state at job completion
    -- RETURNS:
    --      NONE
    --
    -- EXCEPTIONS:
    --      Fatal exceptions raised - all others eaten
    PROCEDURE wait_for_job (
      handle IN NUMBER,
      job_state OUT VARCHAR2
    );
  ---------------------------------------------------------------
    -- The following routines are for internal Oracle consumers
    -- such as consumers of the Data Pump extensibility framework.
    ---------------------------------------------------------------
    -- DATAPUMP_JOB: Is it or is it not?
    FUNCTION datapump_job RETURN BOOLEAN;
  -- Privs - Yes or no?
    FUNCTION has_privs(oper IN VARCHAR2) RETURN BOOLEAN;
  -- Establish remote Data Pump job context
    PROCEDURE establish_remote_context(
      worker_id IN NUMBER,
      remote_link IN VARCHAR2
    );
  PROCEDURE set_remote_worker(worker_id IN NUMBER);
  -- Set up remote Data Pump job context
    PROCEDURE setup_remote_context(
      user_name IN VARCHAR2,
      job_name IN VARCHAR2,
      version IN NUMBER,
      status_xml IN VARCHAR2,
      status_xml_len IN NUMBER,
      more IN NUMBER
    );
  -- To determine ku$_Status object version to use for network operations
    FUNCTION get_status_version(version IN NUMBER) RETURN NUMBER;
  -- Test remote Data Pump job context
    PROCEDURE test_remote_context1010;
  PROCEDURE test_remote_context1020;
  PROCEDURE test_remote_context1120;
  PROCEDURE test_remote_context1210;
  -- LOG_ERROR: Add error to log file and broadcast to all get_status callers
    PROCEDURE log_error (
      handle IN NUMBER,
      message IN VARCHAR2,
      error_number IN NUMBER DEFAULT 0,
      fatal_error IN NUMBER DEFAULT 0,
      log_file_only IN NUMBER DEFAULT 0
    );
  -- Create view into master table for a job
    PROCEDURE create_job_view (
      job_schema IN VARCHAR2,
      job_name IN VARCHAR2,
      view_name IN VARCHAR2,
      view_type IN NUMBER DEFAULT KU$_JOB_VIEW_ALL
    );
  PROCEDURE create_job_view (
      handle IN NUMBER,
      view_name IN VARCHAR2,
      view_type IN NUMBER DEFAULT KU$_JOB_VIEW_ALL
    );
  -- SET_DEBUG: Enable debug/trace features - pre 11.0
    -- PARAMETERS:
    --      on_off          - new switch state.
    --      ip_addr         - IP Address to connected to jdeveloper
    PROCEDURE set_debug (
      on_off IN NUMBER,
      ip_addr IN VARCHAR2 DEFAULT NULL
    );
  -- SET_DEBUG: Enable debug/trace features - 11.0 forward
    -- PARAMETERS:
    --      debug_flags:  Trace/debug flags from /TRACE param, or event, and
    --                    possibly global trace/debug flags
    --      version_flag: Any integer, no default
    PROCEDURE set_debug (
      debug_flags IN BINARY_INTEGER,
      version_flag IN BINARY_INTEGER
    );
  -- TRACE_ENTRY: Write a trace msg. to the current process's trace file
    --      if options debugging is turned on.
    PROCEDURE trace_entry (
      facility IN VARCHAR2,
      msg IN VARCHAR2
    );
  -- Temporary home for clob helper routines
    PROCEDURE client_lob_append (
      value IN VARCHAR2,
      position IN NUMBER,
      as_is IN NUMBER DEFAULT 0
    );
  FUNCTION client_lob_get RETURN CLOB;
  PROCEDURE client_lob_delete;
  PROCEDURE dh_key_exchange(
      handle IN NUMBER,
      a IN VARCHAR2,
      b IN VARCHAR2,
      c OUT VARCHAR2,
      d OUT VARCHAR2
    );
  END DBMS_DATAPUMP;
